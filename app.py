#!/usr/bin/env python3
"""
PDFæ–‡æ¡£è§£ææŸ¥çœ‹å™¨ - Flask Webåº”ç”¨
"""
import os
import uuid
import threading
import json
import base64
import shutil
import time
import requests
from requests.adapters import HTTPAdapter
from datetime import datetime
from pathlib import Path
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed

from flask import Flask, request, jsonify, send_file, send_from_directory, render_template, after_this_request
from flask_cors import CORS

from document_parser import DocumentParser
from config import DEEPLX_API_URL, DEFAULT_SOURCE_LANG, DEFAULT_TARGET_LANG

app = Flask(__name__)
CORS(app)

BASE_DIR = Path(__file__).resolve().parent
UPLOAD_FOLDER = os.path.join(BASE_DIR, 'uploads')
OUTPUT_FOLDER = os.path.join(BASE_DIR, 'outputs')
FRONTEND_DIST = BASE_DIR / 'frontend' / 'dist'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

tasks = {}
DEEPLX_MAX_CONCURRENCY = int(os.environ.get("DEEPLX_MAX_CONCURRENCY", "4"))
DEEPLX_TIMEOUT = float(os.environ.get("DEEPLX_TIMEOUT", "30"))
DEEPLX_MAX_RETRIES = int(os.environ.get("DEEPLX_MAX_RETRIES", "2"))
DEEPLX_RATE_LIMIT = float(os.environ.get("DEEPLX_RATE_LIMIT", "0.3"))
DEEPLX_HEALTH_TTL = float(os.environ.get("DEEPLX_HEALTH_TTL", "60"))
DEEPLX_CONNECTION_POOL = int(os.environ.get("DEEPLX_CONNECTION_POOL", str(DEEPLX_MAX_CONCURRENCY * 4)))

deeplx_session = requests.Session()
deeplx_adapter = HTTPAdapter(pool_connections=DEEPLX_CONNECTION_POOL, pool_maxsize=DEEPLX_CONNECTION_POOL)
deeplx_session.mount("http://", deeplx_adapter)
deeplx_session.mount("https://", deeplx_adapter)

_DEEPLX_HEALTH_CACHE = {"ts": 0.0, "ok": False}

# æ–‡ä»¶æ¸…ç†é…ç½®ï¼ˆç§’ï¼‰
FILE_MAX_AGE = 24 * 60 * 60  # 24å°æ—¶


def cleanup_old_files():
    """æ¸…ç†è¶…è¿‡24å°æ—¶çš„ä¸Šä¼ æ–‡ä»¶å’Œè¾“å‡ºæ–‡ä»¶"""
    current_time = time.time()
    cleaned_count = 0

    # æ¸…ç†uploadsç›®å½•
    if os.path.exists(UPLOAD_FOLDER):
        for filename in os.listdir(UPLOAD_FOLDER):
            filepath = os.path.join(UPLOAD_FOLDER, filename)
            if os.path.isfile(filepath):
                file_age = current_time - os.path.getmtime(filepath)
                if file_age > FILE_MAX_AGE:
                    try:
                        os.remove(filepath)
                        cleaned_count += 1
                        print(f"âœ“ æ¸…ç†æ—§æ–‡ä»¶: {filename}")
                    except Exception as e:
                        print(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥ {filename}: {e}")

    # æ¸…ç†outputsç›®å½•
    if os.path.exists(OUTPUT_FOLDER):
        for filename in os.listdir(OUTPUT_FOLDER):
            filepath = os.path.join(OUTPUT_FOLDER, filename)
            if os.path.isfile(filepath):
                file_age = current_time - os.path.getmtime(filepath)
                if file_age > FILE_MAX_AGE:
                    try:
                        os.remove(filepath)
                        cleaned_count += 1
                        print(f"âœ“ æ¸…ç†æ—§æ–‡ä»¶: {filename}")
                    except Exception as e:
                        print(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥ {filename}: {e}")

    if cleaned_count > 0:
        print(f"âœ… å…±æ¸…ç† {cleaned_count} ä¸ªè¿‡æœŸæ–‡ä»¶")


def start_cleanup_scheduler():
    """å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡"""
    import time

    def cleanup_loop():
        while True:
            time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
            cleanup_old_files()

    cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
    cleanup_thread.start()
    print("ğŸ§¹ æ–‡ä»¶æ¸…ç†æœåŠ¡å·²å¯åŠ¨ï¼ˆæ¯å°æ—¶æ£€æŸ¥ï¼Œæ¸…ç†è¶…è¿‡24å°æ—¶çš„æ–‡ä»¶ï¼‰")


def _is_pdf_file(path: str) -> bool:
    try:
        with open(path, "rb") as f:
            return f.read(5) == b"%PDF-"
    except OSError:
        return False


class ParseTask:
    def __init__(self, task_id: str, filename: str):
        self.task_id = task_id
        self.filename = filename
        self.status = "pending"
        self.progress = 0
        self.message = "ç­‰å¾…å¤„ç†..."
        self.result = None
        self.error = None
        self.pdf_path = None
        self.created_at = datetime.now()

    def to_dict(self):
        return {
            "task_id": self.task_id,
            "filename": self.filename,
            "status": self.status,
            "progress": self.progress,
            "message": self.message,
            "error": self.error,
            "created_at": self.created_at.isoformat()
        }


def process_parse(task_id: str, input_path: str):
    task = tasks.get(task_id)
    if not task:
        return
    try:
        task.status = "parsing"
        task.progress = 10
        task.message = "æ­£åœ¨ä¸Šä¼ æ–‡ä»¶..."
        parser = DocumentParser()
        task.progress = 30
        task.message = "æ­£åœ¨è§£ææ–‡æ¡£..."
        result = parser.parse(file_path=input_path)
        task.progress = 90
        task.message = "å¤„ç†å®Œæˆ"
        task.result = result
        # ä»…åœ¨åŸæ–‡ä»¶ä¸ºPDFæ—¶æ‰æä¾›é¢„è§ˆ
        if input_path.lower().endswith(".pdf"):
            task_output_dir = os.path.join(OUTPUT_FOLDER, task_id)
            os.makedirs(task_output_dir, exist_ok=True)
            pdf_dest = os.path.join(task_output_dir, "original.pdf")
            shutil.copy2(input_path, pdf_dest)
            task.pdf_path = pdf_dest
        task.status = "completed"
        task.progress = 100
        task.message = "è§£æå®Œæˆ!"
    except Exception as e:
        task.status = "failed"
        task.error = str(e)
        task.message = f"å¤„ç†å¤±è´¥: {str(e)}"
        import traceback
        traceback.print_exc()
        # è§£æå¤±è´¥æ—¶åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
        if os.path.exists(input_path):
            try:
                os.remove(input_path)
                print(f"âœ“ å·²åˆ é™¤ä¸Šä¼ æ–‡ä»¶: {input_path}")
            except Exception as e2:
                print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {e2}")


def _deeplx_health_check(texts, source_lang, target_lang):
    """å¯¹DeepLXåšç¼“å­˜å¥åº·æ£€æµ‹ï¼Œé¿å…æ¯æ¬¡æ‰¹é‡è°ƒç”¨éƒ½é¢å¤–è¯·æ±‚ä¸€æ¬¡"""
    now = time.time()
    last_ts = _DEEPLX_HEALTH_CACHE.get("ts", 0.0)
    if (now - last_ts) < DEEPLX_HEALTH_TTL and _DEEPLX_HEALTH_CACHE.get("ok"):
        return

    sample = next((t for t in texts if (t or "").strip()), "")
    if not sample:
        return

    payload = {
        "text": sample[:200],
        "source_lang": source_lang or DEFAULT_SOURCE_LANG,
        "target_lang": target_lang or DEFAULT_TARGET_LANG,
    }

    try:
        deeplx_session.post(
            DEEPLX_API_URL,
            json=payload,
            timeout=(3, min(15, DEEPLX_TIMEOUT))
        )
        _DEEPLX_HEALTH_CACHE.update({"ts": now, "ok": True})
    except Exception as exc:
        _DEEPLX_HEALTH_CACHE.update({"ts": now, "ok": False})
        print(f"âš ï¸ DeepLXè¿é€šæ€§æ£€æµ‹å¤±è´¥ï¼ˆå°†ç»§ç»­å°è¯•ç¿»è¯‘ï¼‰: {exc}", flush=True)


def translate_via_deeplx(text: str, source_lang: str, target_lang: str) -> str:
    if not DEEPLX_API_URL:
        raise ValueError("DEEPLX_API_URL æœªé…ç½®")

    payload = {
        "text": text,
        "source_lang": source_lang or DEFAULT_SOURCE_LANG,
        "target_lang": target_lang or DEFAULT_TARGET_LANG
    }

    last_error = None
    for attempt in range(1, DEEPLX_MAX_RETRIES + 1):
        try:
            if attempt > 1:
                wait_time = min(2 ** (attempt - 1), 5)
                print(f"â³ DeepLXé‡è¯•ç­‰å¾… {wait_time} ç§’ï¼ˆç¬¬ {attempt}/{DEEPLX_MAX_RETRIES} æ¬¡ï¼‰...", flush=True)
                time.sleep(wait_time)

            start_ts = time.time()
            response = deeplx_session.post(
                DEEPLX_API_URL,
                json=payload,
                timeout=(5, DEEPLX_TIMEOUT)
            )
            elapsed = time.time() - start_ts
            print(f"ğŸ” DeepLXå“åº”: status={response.status_code} time={elapsed:.2f}s", flush=True)

            if response.status_code == 429:
                raise ValueError("DeepLXæ¥å£è§¦å‘é™æµ(429)ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½æ‰¹é‡å¤§å°/é¢‘ç‡ã€‚")

            response.raise_for_status()
            data = response.json()

            if data.get("code") == 200:
                return data.get("data", text)

            raise ValueError(data.get("message") or data.get("msg") or "DeepLXç¿»è¯‘å¤±è´¥")
        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as exc:
            last_error = exc
            print(f"âš ï¸ DeepLXè¯·æ±‚å¼‚å¸¸: {exc}", flush=True)
            continue
        except Exception as exc:
            last_error = exc
            print(f"âš ï¸ DeepLXç¿»è¯‘é”™è¯¯: {exc}", flush=True)
            continue

    raise ValueError(f"DeepLXç¿»è¯‘å¤±è´¥: {last_error}")


def translate_via_openai(text: str, config: dict, source_lang: str, target_lang: str) -> str:
    base_url = (config or {}).get("base_url")
    api_key = (config or {}).get("api_key")
    model = (config or {}).get("model")

    if not base_url or not api_key or not model:
        raise ValueError("ç¼ºå°‘OpenAIç¿»è¯‘é…ç½®")

    url = base_url.rstrip('/') + "/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    prompt = f"Translate the following text from {source_lang or 'Source Language'} to {target_lang or 'Target Language'}:\n\n{text}"
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "You are a professional translation engine."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,
        "stream": False
    }

    response = requests.post(url, headers=headers, json=payload, timeout=90)
    response.raise_for_status()
    data = response.json()
    choices = data.get("choices", [])
    if not choices:
        raise ValueError("OpenAIç¿»è¯‘è¿”å›ä¸ºç©º")
    return choices[0]["message"]["content"].strip()


def batch_translate_via_deeplx(texts, source_lang, target_lang):
    if not texts:
        return []

    _deeplx_health_check(texts, source_lang, target_lang)

    # ä¼˜åŒ–ï¼šåˆå¹¶å°æ–‡æœ¬å—ä»¥å‡å°‘è¯·æ±‚æ¬¡æ•°
    MAX_CHUNK_SIZE = 3000  # DeepLXå¯ä»¥å¤„ç†è¾ƒå¤§çš„æ–‡æœ¬å—
    merged_chunks = []
    current_chunk = []
    current_size = 0

    for text in texts:
        if not text or not text.strip():
            # ä¿ç•™ç©ºæ–‡æœ¬çš„ä½ç½®
            if current_chunk:
                merged_chunks.append(("\n\n".join(current_chunk), len(current_chunk)))
                current_chunk = []
                current_size = 0
            merged_chunks.append(("", 1))
            continue

        text_len = len(text)
        # å¦‚æœå•ä¸ªæ–‡æœ¬å°±è¶…è¿‡é™åˆ¶ï¼Œå•ç‹¬å¤„ç†
        if text_len > MAX_CHUNK_SIZE:
            if current_chunk:
                merged_chunks.append(("\n\n".join(current_chunk), len(current_chunk)))
                current_chunk = []
                current_size = 0
            merged_chunks.append((text, 1))
        # å¦‚æœåŠ ä¸Šå½“å‰æ–‡æœ¬ä¼šè¶…è¿‡é™åˆ¶ï¼Œå…ˆä¿å­˜å½“å‰å—
        elif current_size + text_len + 2 > MAX_CHUNK_SIZE:
            if current_chunk:
                merged_chunks.append(("\n\n".join(current_chunk), len(current_chunk)))
            current_chunk = [text]
            current_size = text_len
        # å¦åˆ™ç´¯ç§¯åˆ°å½“å‰å—
        else:
            current_chunk.append(text)
            current_size += text_len + 2

    # ä¿å­˜æœ€åä¸€å—
    if current_chunk:
        merged_chunks.append(("\n\n".join(current_chunk), len(current_chunk)))

    print(f"ğŸ“Š ä¼˜åŒ–å‰: {len(texts)} ä¸ªæ–‡æœ¬å—ï¼Œä¼˜åŒ–å: {len(merged_chunks)} ä¸ªè¯·æ±‚", flush=True)

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ç¿»è¯‘
    results = []
    success_count = 0
    last_error = None

    def translate_chunk(chunk_text):
        if not chunk_text:
            return chunk_text
        try:
            return translate_via_deeplx(chunk_text, source_lang, target_lang)
        except Exception as exc:
            print(f"âš ï¸ ç¿»è¯‘å—å¤±è´¥: {exc}", flush=True)
            return chunk_text

    with ThreadPoolExecutor(max_workers=DEEPLX_MAX_CONCURRENCY) as executor:
        futures = []
        for chunk_text, count in merged_chunks:
            future = executor.submit(translate_chunk, chunk_text)
            futures.append((future, count))
            # æ·»åŠ å°å»¶è¿Ÿé¿å…ç¬é—´å¤§é‡è¯·æ±‚
            if DEEPLX_RATE_LIMIT > 0:
                time.sleep(DEEPLX_RATE_LIMIT / DEEPLX_MAX_CONCURRENCY)

        # æ”¶é›†ç»“æœ
        for future, count in futures:
            try:
                translated = future.result()
                if not translated:
                    results.append(translated)
                elif count == 1:
                    results.append(translated)
                    if translated:
                        success_count += 1
                else:
                    # æ‹†åˆ†åˆå¹¶çš„å—
                    parts = translated.split("\n\n")
                    results.extend(parts)
                    success_count += len([p for p in parts if p])
            except Exception as exc:
                last_error = exc
                results.extend([""] * count)

    if success_count == 0 and last_error is not None:
        raise ValueError(str(last_error))

    return results


def batch_translate_via_openai(texts, config, source_lang, target_lang):
    results = []
    for text in texts:
        if not text:
            results.append(text)
            continue
        translated = translate_via_openai(text, config, source_lang, target_lang)
        results.append(translated)
    return results


@app.route('/')
def serve_frontend_index():
    if FRONTEND_DIST.joinpath('index.html').exists():
        return send_from_directory(FRONTEND_DIST, 'index.html')
    return render_template('index.html')


@app.route('/viewer')
def render_viewer():
    return render_template('index.html')


@app.route('/assets/<path:filename>')
def serve_frontend_assets(filename):
    assets_dir = FRONTEND_DIST / 'assets'
    if assets_dir.exists():
        return send_from_directory(assets_dir, filename)
    return jsonify({"error": "å‰ç«¯é™æ€èµ„æºå°šæœªæ„å»º"}), 404


@app.route('/<path:path>')
def serve_frontend_static(path):
    target = FRONTEND_DIST / path
    if target.exists() and target.is_file():
        return send_from_directory(FRONTEND_DIST, path)
    return serve_frontend_index()


@app.route('/api/parse', methods=['POST'])
def parse():
    if 'file' not in request.files:
        return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400
    task_id = str(uuid.uuid4())[:8]
    filename = f"{task_id}_{file.filename}"
    input_path = os.path.join(UPLOAD_FOLDER, filename)
    file.save(input_path)
    task = ParseTask(task_id, file.filename)
    tasks[task_id] = task
    thread = threading.Thread(target=process_parse, args=(task_id, input_path))
    thread.daemon = True
    thread.start()
    return jsonify({"task_id": task_id, "message": "ä»»åŠ¡å·²åˆ›å»º"})


@app.route('/api/task/<task_id>')
def get_task(task_id):
    task = tasks.get(task_id)
    if not task:
        return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    return jsonify(task.to_dict())


@app.route('/api/result/<task_id>')
def get_result(task_id):
    task = tasks.get(task_id)
    if not task:
        return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    if task.status != 'completed' or not task.result:
        return jsonify({"error": "ç»“æœæœªå‡†å¤‡å¥½"}), 400
    return jsonify({
        "markdown": task.result.get("markdown", ""),
        "content_list": task.result.get("content_list", []),
        "page_mappings": task.result.get("page_mappings", {})
    })


@app.route('/api/pdf/<task_id>')
def get_pdf(task_id):
    # ä¼˜å…ˆä»ä»»åŠ¡å¯¹è±¡è·å–
    task = tasks.get(task_id)
    if task and task.pdf_path and os.path.exists(task.pdf_path):
        if _is_pdf_file(task.pdf_path):
            print(f"âœ“ è¿”å›PDFæ–‡ä»¶(ä»ä»»åŠ¡): {task.pdf_path}")
            return send_file(task.pdf_path, mimetype='application/pdf')
        print(f"âš ï¸ PDFè¯·æ±‚å¤±è´¥: æ–‡ä»¶ä¸æ˜¯PDF {task.pdf_path}")
    # ä»»åŠ¡å¯¹è±¡ä¸å­˜åœ¨æ—¶ï¼Œå°è¯•ä»outputsç›®å½•æŸ¥æ‰¾
    pdf_path = os.path.join(OUTPUT_FOLDER, task_id, "original.pdf")
    if os.path.exists(pdf_path) and _is_pdf_file(pdf_path):
        print(f"âœ“ è¿”å›PDFæ–‡ä»¶(ä»outputs): {pdf_path}")
        return send_file(pdf_path, mimetype='application/pdf')
    print(f"âš ï¸ PDFè¯·æ±‚å¤±è´¥: ä»»åŠ¡ {task_id} çš„PDFæ–‡ä»¶ä¸å­˜åœ¨")
    return jsonify({"error": "PDFæ–‡ä»¶ä¸å­˜åœ¨"}), 404


@app.route('/api/image/<task_id>/<image_name>')
def get_image(task_id, image_name):
    task = tasks.get(task_id)
    if not task or not task.result:
        return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    images = task.result.get("images", {})
    if image_name not in images:
        return jsonify({"error": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404
    return send_file(BytesIO(images[image_name]), mimetype='image/png')


@app.route('/api/translate', methods=['POST'])
def translate_text():
    data = request.get_json(force=True)
    text = (data.get("text") or "").strip()
    if not text:
        return jsonify({"error": "ç¼ºå°‘æ–‡æœ¬å†…å®¹"}), 400

    provider_raw = data.get("provider", "deeplx")
    provider = (provider_raw or "").strip().lower()
    source_lang = data.get("source_lang") or DEFAULT_SOURCE_LANG
    target_lang = data.get("target_lang") or DEFAULT_TARGET_LANG

    try:
        if provider == "openai":
            translated = translate_via_openai(text, data.get("config"), source_lang, target_lang)
        else:
            translated = translate_via_deeplx(text, source_lang, target_lang)
        return jsonify({"translated_text": translated})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/translate_batch', methods=['POST'])
def translate_batch():
    data = request.get_json(force=True)
    chunks = data.get("chunks")
    if not isinstance(chunks, list) or not chunks:
        return jsonify({"error": "ç¼ºå°‘ç¿»è¯‘å†…å®¹"}), 400

    texts = [(chunk.get("text") or "") for chunk in chunks]
    provider_raw = data.get("provider", "deeplx")
    provider = (provider_raw or "").strip().lower()
    source_lang = data.get("source_lang") or DEFAULT_SOURCE_LANG
    target_lang = data.get("target_lang") or DEFAULT_TARGET_LANG
    print(
        f"ğŸŒ translate_batch provider_raw={provider_raw!r} provider={provider} chunks={len(texts)} source={source_lang} target={target_lang}",
        flush=True
    )
    if texts:
        lengths = [len(t or "") for t in texts]
        max_len = max(lengths) if lengths else 0
        min_len = min(lengths) if lengths else 0
        print(f"ğŸ§© chunk_len min={min_len} max={max_len}", flush=True)

    try:
        if provider == "openai":
            print("â¡ï¸ using openai", flush=True)
            translations = batch_translate_via_openai(texts, data.get("config"), source_lang, target_lang)
        else:
            print("â¡ï¸ using deeplx", flush=True)
            translations = batch_translate_via_deeplx(texts, source_lang, target_lang)
        return jsonify({"translations": translations})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/download_pdf/<task_id>', methods=['POST'])
def download_translated_pdf(task_id):
    """ä¸‹è½½ç¿»è¯‘åçš„PDFæ–‡ä»¶"""
    task = tasks.get(task_id)
    if not task:
        return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    if task.status != 'completed' or not task.result:
        return jsonify({"error": "ä»»åŠ¡æœªå®Œæˆ"}), 400

    data = request.get_json(force=True) if request.is_json else {}
    content_list = data.get("content_list", [])

    try:
        from pdf_generator import markdown_to_pdf, content_list_to_markdown

        # è·å–å›¾ç‰‡çš„è¾…åŠ©å‡½æ•°
        def get_image_data(tid, image_name):
            t = tasks.get(tid)
            if t and t.result:
                imgs = t.result.get("images", {})
                return imgs.get(image_name)
            return None

        # æ„å»ºMarkdownå†…å®¹
        if content_list:
            # ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„ç¿»è¯‘åå†…å®¹
            markdown_content = content_list_to_markdown(content_list, task.result.get("images", {}))
        else:
            # ä½¿ç”¨åŸå§‹Markdown
            markdown_content = task.result.get("markdown", "")

        if not markdown_content:
            return jsonify({"error": "æ²¡æœ‰å¯å¯¼å‡ºçš„å†…å®¹"}), 400

        # ç”ŸæˆPDF
        output_filename = f"translated_{task_id}.pdf"
        output_path = os.path.join(OUTPUT_FOLDER, output_filename)

        markdown_to_pdf(
            markdown_content,
            output_path,
            images=task.result.get("images", {}),
            task_id=task_id,
            get_image_func=get_image_data
        )

        # åœ¨å“åº”å®Œæˆååˆ é™¤ç”Ÿæˆçš„PDFæ–‡ä»¶
        @after_this_request
        def cleanup(response):
            try:
                if os.path.exists(output_path):
                    os.remove(output_path)
                    print(f"âœ“ å·²åˆ é™¤ä¸´æ—¶PDF: {output_path}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ä¸´æ—¶PDFå¤±è´¥: {e}")
            return response

        return send_file(
            output_path,
            as_attachment=True,
            download_name=f"translated_{task.filename}",
            mimetype='application/pdf'
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"PDFç”Ÿæˆå¤±è´¥: {str(e)}"}), 500


@app.route('/api/download/<task_id>/<format_type>', methods=['POST'])
def download_document(task_id, format_type):
    """ä¸‹è½½å¤šç§æ ¼å¼çš„æ–‡æ¡£"""
    task = tasks.get(task_id)
    if not task:
        return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    if task.status != 'completed' or not task.result:
        return jsonify({"error": "ä»»åŠ¡æœªå®Œæˆ"}), 400

    data = request.get_json(force=True) if request.is_json else {}
    content_list = data.get("content_list", [])

    # è·å–åŸºç¡€æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
    base_filename = os.path.splitext(task.filename)[0]

    try:
        if format_type == 'markdown':
            return download_as_markdown(task, content_list, base_filename)
        elif format_type == 'html':
            return download_as_html(task, content_list, base_filename)
        elif format_type == 'docx':
            return download_as_docx(task, content_list, base_filename)
        elif format_type == 'json':
            return download_as_json(task, content_list, base_filename)
        elif format_type == 'latex':
            return download_as_latex(task, content_list, base_filename)
        else:
            return jsonify({"error": f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}"}), 400
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"å¯¼å‡ºå¤±è´¥: {str(e)}"}), 500


def get_content_markdown(task, content_list):
    """ä»content_listæˆ–task.resultè·å–Markdownå†…å®¹"""
    from pdf_generator import content_list_to_markdown
    if content_list:
        return content_list_to_markdown(content_list, task.result.get("images", {}))
    return task.result.get("markdown", "")


def download_as_markdown(task, content_list, base_filename):
    """ä¸‹è½½ä¸ºMarkdownæ ¼å¼"""
    from pdf_generator import content_list_to_markdown

    if content_list:
        markdown_content = content_list_to_markdown(content_list, task.result.get("images", {}))
    else:
        markdown_content = task.result.get("markdown", "")

    if not markdown_content:
        return jsonify({"error": "æ²¡æœ‰å¯å¯¼å‡ºçš„å†…å®¹"}), 400

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.md")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(markdown_content)

    @after_this_request
    def cleanup(response):
        try:
            if os.path.exists(output_path):
                os.remove(output_path)
        except Exception:
            pass
        return response

    return send_file(
        output_path,
        as_attachment=True,
        download_name=f"{base_filename}.md",
        mimetype='text/markdown'
    )


def _has_translated_content(content_list):
    """æ£€æŸ¥content_listä¸­æ˜¯å¦åŒ…å«ç¿»è¯‘åçš„å†…å®¹"""
    if not content_list:
        return False
    for item in content_list:
        if item.get('translated_text'):
            return True
    return False


def download_as_html(task, content_list, base_filename):
    """ä¸‹è½½ä¸ºHTMLæ ¼å¼ - æœ‰ç¿»è¯‘å†…å®¹æ—¶ä½¿ç”¨æœ¬åœ°è½¬æ¢ï¼Œå¦åˆ™ç”¨MinerUåŸæ–‡"""
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘å†…å®¹
    has_translation = _has_translated_content(content_list)

    # å¦‚æœæ²¡æœ‰ç¿»è¯‘å†…å®¹ï¼Œå¯ä»¥ä½¿ç”¨MinerUç”Ÿæˆçš„åŸæ–‡HTML
    if not has_translation:
        export_files = task.result.get("export_files", {})
        mineru_html = export_files.get("html")
        if mineru_html:
            print(f"âœ“ ä½¿ç”¨MinerUç”Ÿæˆçš„HTMLæ–‡ä»¶ï¼ˆåŸæ–‡ï¼‰")
            output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.html")
            with open(output_path, 'wb') as f:
                f.write(mineru_html)

            @after_this_request
            def cleanup(response):
                try:
                    if os.path.exists(output_path):
                        os.remove(output_path)
                except Exception:
                    pass
                return response

            return send_file(
                output_path,
                as_attachment=True,
                download_name=f"{base_filename}.html",
                mimetype='text/html'
            )

    # æœ‰ç¿»è¯‘å†…å®¹ï¼Œä½¿ç”¨æœ¬åœ°è½¬æ¢
    print(f"âœ“ ä½¿ç”¨æœ¬åœ°è½¬æ¢ç”ŸæˆHTMLï¼ˆå«è¯‘æ–‡ï¼‰")
    import markdown
    from pdf_generator import content_list_to_markdown

    if content_list:
        markdown_content = content_list_to_markdown(content_list, task.result.get("images", {}))
    else:
        markdown_content = task.result.get("markdown", "")

    if not markdown_content:
        return jsonify({"error": "æ²¡æœ‰å¯å¯¼å‡ºçš„å†…å®¹"}), 400

    # è½¬æ¢Markdownä¸ºHTML
    md = markdown.Markdown(extensions=['tables', 'fenced_code', 'toc'])
    html_body = md.convert(markdown_content)

    # å¤„ç†å›¾ç‰‡ - å°†å›¾ç‰‡è½¬ä¸ºbase64å†…åµŒ
    images = task.result.get("images", {})
    for img_name, img_data in images.items():
        if img_data:
            img_base64 = base64.b64encode(img_data).decode('utf-8')
            html_body = html_body.replace(
                f'/api/image/{task.task_id}/{img_name}',
                f'data:image/png;base64,{img_base64}'
            )
            html_body = html_body.replace(
                f'images/{img_name}',
                f'data:image/png;base64,{img_base64}'
            )

    html_content = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{base_filename}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 40px 20px; line-height: 1.8; color: #333; }}
        h1, h2, h3 {{ margin-top: 1.5em; color: #1a1a1a; }}
        img {{ max-width: 100%; height: auto; }}
        pre {{ background: #f5f5f5; padding: 15px; border-radius: 5px; overflow-x: auto; }}
        code {{ background: #f5f5f5; padding: 2px 6px; border-radius: 3px; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px 12px; }}
    </style>
</head>
<body>
{html_body}
</body>
</html>'''

    output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.html")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)

    @after_this_request
    def cleanup(response):
        try:
            if os.path.exists(output_path):
                os.remove(output_path)
        except Exception:
            pass
        return response

    return send_file(
        output_path,
        as_attachment=True,
        download_name=f"{base_filename}.html",
        mimetype='text/html'
    )


def download_as_docx(task, content_list, base_filename):
    """ä¸‹è½½ä¸ºDOCXæ ¼å¼ - æœ‰ç¿»è¯‘å†…å®¹æ—¶ä½¿ç”¨æœ¬åœ°è½¬æ¢ï¼Œå¦åˆ™ç”¨MinerUåŸæ–‡"""
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘å†…å®¹
    has_translation = _has_translated_content(content_list)

    # å¦‚æœæ²¡æœ‰ç¿»è¯‘å†…å®¹ï¼Œå¯ä»¥ä½¿ç”¨MinerUç”Ÿæˆçš„åŸæ–‡DOCX
    if not has_translation:
        export_files = task.result.get("export_files", {})
        mineru_docx = export_files.get("docx")
        if mineru_docx:
            print(f"âœ“ ä½¿ç”¨MinerUç”Ÿæˆçš„DOCXæ–‡ä»¶ï¼ˆåŸæ–‡ï¼‰")
            output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.docx")
            with open(output_path, 'wb') as f:
                f.write(mineru_docx)

            @after_this_request
            def cleanup(response):
                try:
                    if os.path.exists(output_path):
                        os.remove(output_path)
                except Exception:
                    pass
                return response

            return send_file(
                output_path,
                as_attachment=True,
                download_name=f"{base_filename}.docx",
                mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
            )

    # æœ‰ç¿»è¯‘å†…å®¹ï¼Œä½¿ç”¨æœ¬åœ°è½¬æ¢
    print(f"âœ“ ä½¿ç”¨æœ¬åœ°è½¬æ¢ç”ŸæˆDOCXï¼ˆå«è¯‘æ–‡ï¼‰")
    from docx import Document
    from docx.shared import Inches, Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    import re

    doc = Document()
    title = doc.add_heading(base_filename, 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    if content_list:
        for item in content_list:
            item_type = item.get('type', 'text')
            text = item.get('translated_text') or item.get('text', '')
            text_level = item.get('text_level')

            if item_type == 'image':
                img_path = item.get('img_path', '')
                img_name = img_path.split('/')[-1] if img_path else ''
                images = task.result.get("images", {})
                if img_name and img_name in images:
                    img_data = images[img_name]
                    if img_data:
                        try:
                            img_stream = BytesIO(img_data)
                            doc.add_picture(img_stream, width=Inches(5))
                        except Exception:
                            pass
                caption = item.get('image_caption', [])
                if caption:
                    p = doc.add_paragraph(' '.join(caption))
                    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
            elif item_type == 'list':
                if text:
                    doc.add_paragraph(text)
                else:
                    list_items = item.get('list_items', [])
                    for li in list_items:
                        doc.add_paragraph(li, style='List Bullet')
            elif text_level and text_level <= 6:
                doc.add_heading(text, level=min(text_level, 9))
            elif text:
                doc.add_paragraph(text)
    else:
        markdown_content = task.result.get("markdown", "")
        for line in markdown_content.split('\n'):
            line = line.strip()
            if not line:
                continue
            if line.startswith('# '):
                doc.add_heading(line[2:], level=1)
            elif line.startswith('## '):
                doc.add_heading(line[3:], level=2)
            elif line.startswith('### '):
                doc.add_heading(line[4:], level=3)
            elif line.startswith('- ') or line.startswith('* '):
                doc.add_paragraph(line[2:], style='List Bullet')
            elif re.match(r'^\d+\. ', line):
                doc.add_paragraph(re.sub(r'^\d+\. ', '', line), style='List Number')
            else:
                doc.add_paragraph(line)

    output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.docx")
    doc.save(output_path)

    @after_this_request
    def cleanup(response):
        try:
            if os.path.exists(output_path):
                os.remove(output_path)
        except Exception:
            pass
        return response

    return send_file(
        output_path,
        as_attachment=True,
        download_name=f"{base_filename}.docx",
        mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    )


def download_as_json(task, content_list, base_filename):
    """ä¸‹è½½ä¸ºJSONæ ¼å¼ï¼ˆåŒ…å«å®Œæ•´ç»“æ„ä¿¡æ¯ï¼‰"""
    # æ„å»ºå®Œæ•´çš„JSONæ•°æ®
    export_data = {
        "filename": task.filename,
        "task_id": task.task_id,
        "created_at": task.created_at.isoformat(),
        "content_list": content_list if content_list else task.result.get("content_list", []),
        "markdown": task.result.get("markdown", ""),
        "page_mappings": task.result.get("page_mappings", {}),
        "metadata": {
            "export_time": datetime.now().isoformat(),
            "format_version": "1.0"
        }
    }

    # ä¸å¯¼å‡ºå›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œåªå¯¼å‡ºå›¾ç‰‡åç§°åˆ—è¡¨
    images = task.result.get("images", {})
    export_data["image_names"] = list(images.keys())

    output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)

    @after_this_request
    def cleanup(response):
        try:
            if os.path.exists(output_path):
                os.remove(output_path)
        except Exception:
            pass
        return response

    return send_file(
        output_path,
        as_attachment=True,
        download_name=f"{base_filename}.json",
        mimetype='application/json'
    )


def download_as_latex(task, content_list, base_filename):
    """ä¸‹è½½ä¸ºLaTeXæ ¼å¼ - æœ‰ç¿»è¯‘å†…å®¹æ—¶ä½¿ç”¨æœ¬åœ°è½¬æ¢ï¼Œå¦åˆ™ç”¨MinerUåŸæ–‡"""
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘å†…å®¹
    has_translation = _has_translated_content(content_list)

    # å¦‚æœæ²¡æœ‰ç¿»è¯‘å†…å®¹ï¼Œå¯ä»¥ä½¿ç”¨MinerUç”Ÿæˆçš„åŸæ–‡LaTeX
    if not has_translation:
        export_files = task.result.get("export_files", {})
        mineru_latex = export_files.get("latex")
        if mineru_latex:
            print(f"âœ“ ä½¿ç”¨MinerUç”Ÿæˆçš„LaTeXæ–‡ä»¶ï¼ˆåŸæ–‡ï¼‰")
            output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.tex")
            with open(output_path, 'wb') as f:
                f.write(mineru_latex)

            @after_this_request
            def cleanup(response):
                try:
                    if os.path.exists(output_path):
                        os.remove(output_path)
                except Exception:
                    pass
                return response

            return send_file(
                output_path,
                as_attachment=True,
                download_name=f"{base_filename}.tex",
                mimetype='application/x-tex'
            )

    # æœ‰ç¿»è¯‘å†…å®¹ï¼Œä½¿ç”¨æœ¬åœ°è½¬æ¢
    print(f"âœ“ ä½¿ç”¨æœ¬åœ°è½¬æ¢ç”ŸæˆLaTeXï¼ˆå«è¯‘æ–‡ï¼‰")
    from pdf_generator import content_list_to_markdown
    import re

    if content_list:
        markdown_content = content_list_to_markdown(content_list, task.result.get("images", {}))
    else:
        markdown_content = task.result.get("markdown", "")

    if not markdown_content:
        return jsonify({"error": "æ²¡æœ‰å¯å¯¼å‡ºçš„å†…å®¹"}), 400

    latex_content = markdown_to_latex(markdown_content, base_filename)

    output_path = os.path.join(OUTPUT_FOLDER, f"{task.task_id}_export.tex")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(latex_content)

    @after_this_request
    def cleanup(response):
        try:
            if os.path.exists(output_path):
                os.remove(output_path)
        except Exception:
            pass
        return response

    return send_file(
        output_path,
        as_attachment=True,
        download_name=f"{base_filename}.tex",
        mimetype='application/x-tex'
    )


def markdown_to_latex(markdown_content, title="Document"):
    """å°†Markdownè½¬æ¢ä¸ºLaTeXæ ¼å¼"""
    import re

    # LaTeXæ–‡æ¡£å¤´
    latex = r'''\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xeCJK}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\geometry{margin=2.5cm}

\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10}
}

\title{''' + escape_latex(title) + r'''}
\date{\today}

\begin{document}
\maketitle

'''

    lines = markdown_content.split('\n')
    in_code_block = False
    code_lang = ''

    for line in lines:
        # ä»£ç å—å¤„ç†
        if line.strip().startswith('```'):
            if not in_code_block:
                in_code_block = True
                code_lang = line.strip()[3:]
                latex += '\\begin{lstlisting}'
                if code_lang:
                    latex += f'[language={code_lang}]'
                latex += '\n'
            else:
                in_code_block = False
                latex += '\\end{lstlisting}\n'
            continue

        if in_code_block:
            latex += line + '\n'
            continue

        # æ ‡é¢˜å¤„ç†
        if line.startswith('# '):
            latex += '\\section{' + escape_latex(line[2:]) + '}\n'
        elif line.startswith('## '):
            latex += '\\subsection{' + escape_latex(line[3:]) + '}\n'
        elif line.startswith('### '):
            latex += '\\subsubsection{' + escape_latex(line[4:]) + '}\n'
        elif line.startswith('#### '):
            latex += '\\paragraph{' + escape_latex(line[5:]) + '}\n'
        # åˆ—è¡¨å¤„ç†
        elif line.strip().startswith('- ') or line.strip().startswith('* '):
            latex += '\\begin{itemize}\n'
            latex += '\\item ' + escape_latex(line.strip()[2:]) + '\n'
            latex += '\\end{itemize}\n'
        elif re.match(r'^\d+\. ', line.strip()):
            latex += '\\begin{enumerate}\n'
            latex += '\\item ' + escape_latex(re.sub(r'^\d+\. ', '', line.strip())) + '\n'
            latex += '\\end{enumerate}\n'
        # å›¾ç‰‡å¤„ç†
        elif '![' in line:
            match = re.search(r'!\[([^\]]*)\]\(([^)]+)\)', line)
            if match:
                alt_text = match.group(1)
                img_path = match.group(2)
                latex += '\\begin{figure}[h]\n'
                latex += '\\centering\n'
                latex += f'% \\includegraphics[width=0.8\\textwidth]{{{img_path}}}\n'
                if alt_text:
                    latex += f'\\caption{{{escape_latex(alt_text)}}}\n'
                latex += '\\end{figure}\n'
        # æ•°å­¦å…¬å¼å¤„ç† - ä¿æŒåŸæ ·
        elif line.strip().startswith('$$') or line.strip().endswith('$$'):
            latex += line + '\n'
        elif '$' in line:
            latex += process_inline_math(line) + '\n'
        # ç©ºè¡Œ
        elif not line.strip():
            latex += '\n'
        # æ™®é€šæ®µè½
        else:
            latex += escape_latex(line) + '\n'

    latex += r'''
\end{document}
'''
    return latex


def escape_latex(text):
    """è½¬ä¹‰LaTeXç‰¹æ®Šå­—ç¬¦"""
    if not text:
        return ''
    # ä¿ç•™æ•°å­¦å…¬å¼ä¸­çš„å†…å®¹
    parts = []
    last_end = 0
    # åŒ¹é… $...$ æˆ– $$...$$ çš„æ•°å­¦å…¬å¼
    import re
    for match in re.finditer(r'\$\$.*?\$\$|\$.*?\$', text):
        # è½¬ä¹‰å…¬å¼å‰çš„æ–‡æœ¬
        before = text[last_end:match.start()]
        before = _escape_latex_chars(before)
        parts.append(before)
        # ä¿æŒå…¬å¼åŸæ ·
        parts.append(match.group())
        last_end = match.end()
    # è½¬ä¹‰å‰©ä½™æ–‡æœ¬
    after = text[last_end:]
    after = _escape_latex_chars(after)
    parts.append(after)
    return ''.join(parts)


def _escape_latex_chars(text):
    """è½¬ä¹‰LaTeXç‰¹æ®Šå­—ç¬¦ï¼ˆä¸å«æ•°å­¦å…¬å¼ï¼‰"""
    if not text:
        return ''
    chars = {
        '&': r'\&',
        '%': r'\%',
        '#': r'\#',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '^': r'\textasciicircum{}',
    }
    for char, replacement in chars.items():
        text = text.replace(char, replacement)
    # å¤„ç†åæ–œæ ï¼ˆä½†ä¸å¤„ç†å·²æœ‰çš„LaTeXå‘½ä»¤ï¼‰
    text = re.sub(r'\\(?![a-zA-Z])', r'\\textbackslash{}', text)
    return text


def process_inline_math(line):
    """å¤„ç†è¡Œå†…æ•°å­¦å…¬å¼"""
    # ä¿æŒ $...$ æ ¼å¼çš„å…¬å¼ä¸å˜
    return escape_latex(line)


# å¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡æ¸…ç†å¹¶å¯åŠ¨å®šæ—¶æ¸…ç†æœåŠ¡
cleanup_old_files()
start_cleanup_scheduler()


if __name__ == '__main__':
    print("=" * 50)
    print("ğŸ“„ PDFæ–‡æ¡£è§£ææŸ¥çœ‹å™¨")
    print("=" * 50)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:8080")
    print("=" * 50)
    app.run(host='0.0.0.0', port=8080, debug=True)
